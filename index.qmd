---
title: "TriTrypDT - Transformando uma base de dados biológica (TriTrypDB) em uma tabela"
author: "Laila Viana"
toc: true
toc-location: left
format: 
  html:
    code-fold: true
    smooth-scroll: true
editor: visual
theme: cosmo

---

```{css}
#| echo: false
body{
  text-align: justify;
}
```


## TriTrypDB

O [TriTrypDB](https://tritrypdb.org/tritrypdb/app) é um banco de dados biológico que disponibiliza para a comunidade científica dados genômicos e fenotípicos de várias espécies de tripanossomatídeos. Os tripanossomatídeos são protozoários que possuem flagelo único e são parasitos obrigatórios de plantas e animais. Dentre os parasitos interesse médico, temos nessa família dois gêneros: *Leishmania* e *Trypanosoma*. 

### Gênero *Leishmania*

O gênero *Leishmania* possui espécies que causam Leishmaniose Visceral e Leishmaniose Cutânea, que causa feridas na pele. A Leishmaniose Visceral (LV) é a forma mais grave, e quando não tratada, 90% dos casos podem ter como desfecho a morte, devido ao envolvimento sistêmico causado pela presença dos parasitos em órgãos como medula óssea, baço e fígado. A Leishmaniose Cutânea produz lesões de pele nodulares e indolores que aumentam, sofrem ulceração no centro e podem persistir por meses a anos. Em alguns casos, os parasitos podem afetar áreas de mucosa, gerando a Leishmaniose Mucocutânea que pode provocar mutilação do nariz e do palato.

![](images/leish.png)

### Gênero *Trypanosoma*

Já o gênero *Trypanosoma* possui duas espécies que causam doença no homem, *Trypanosoma cruzi* sendo responsável pela Doença de Chagas nas Américas e *Trypanosoma brucei* na África, causando a Doença do Sono.\
\
![](images/brucei.jpg)

#### *Trypanosoma cruzi*

O *Trypanosoma cruzi* é o agente etiológico da Doença de Chagas, que afeta mais de 8 milhões de pessoas na América Latina e coloca em risco mais de 25 milhões. A doença é caracterizada por duas fases, a aguda e a crônica, sendo a aguda muito complicada de ser diagnosticada evoluindo assim para a fase crônica. Na fase crônica o paciente pode ficar sem nenhuma manifestação clínica ou pode evoluir para as formas cardíacas ou digestivas, onde há aumento anormal do esôfago e do cólon. 

#### *Trypanosoma brucei*

Já o *Trypanosoma brucei* é o agente etiológico da Doença do Sono, também conhecida como Tripanossomíase Africana Humana. Essa doença ocorre na África Subsaariana (36 países) e é transmitida por uma mosca chamada tsé-tsé. Cerca de 55 milhões de pessoas estão em risco de adquirir essa doença, sendo 3 milhões em risco considerado alto. Essa infecção afeta o sistema nervoso central e causa distúrbios neurológicos graves, podendo levar a pessoa à morte.

## Importância de se estudar esses parasitos

Esses parasitos são causadores de doenças negligênciadas, ou seja, afetam populações pobres principalmente em regiões da África e América Latina, levando à morte mais de 1 milhão de pessoas anualmente. Geralmente medidas preventivas são conhecidas mas não são disponíveis nas áreas mais pobres do mundo. Algumas dessas doenças chegam a possuir tratamento, mas em alguns casos podem ser tóxicos e ineficazes, como é o caso do tratamento para a doença de Chagas. Sendo assim, é importante que mais estudos sejam feitos a respeito da biologia desses parasitos para que sirvam de base para o surgirmento de novas opções de tratamento e também possibilitem o desenvolvimento de vacinas.

## Acesso aos arquivos no TriTrypDB

O TriTrypDB é um repositório excelente para buscar dados sobre os tripanossomatídeos. Entretanto, caso a gente queira buscar os genomas, as CDS (coding sequences), transcritos e proteínas de cada espécie depositada pode ser um pouco trabalhoso. Vou detalhar a seguir o passo a passo de como é feito através do site:\
\
- Passo 1: ao acessar o [TriTrypDB](https://tritrypdb.org/tritrypdb/app) chegamos nessa página como ilustrado na figura abaixo. O primeiro passo é clicar em **Data.**

\
![](images/site1.png)\

\- Passo 2: ao clicar em **Data** ele nos dá algumas opções, devemos clicar então em **Download Data Files.**

\
![](images/site2.png)\

\- Passo 3: ao clicar em **Download Data Files** ele abre uma página com vários links referentes à diferentes realeases que são feitos dos dados dos organismos presentes no banco de dados. O ideal é sempre começar a trabalhar com o mais atual, no caso **Current_Release**. Sendo assim, clicamos nele.

\
![](images/site3.png)\

\- Passo 4: ao clicar em **Current_Release** ele abre uma nova página com os links para cada organismo presente no banco de dados. Vamos supor que vamos trabalhar com *Trypanosoma cruzi* Esmeraldo-Like e assim buscamos ele e clicamos no link.

\
![](images/site4.png)\

\- Passo 5: após selecionar o organismo que você quer baixar os dados, aparece uma lista com links contendo diferentes formatos de arquivos. Em geral, os arquivos mais utilizados são do formato fasta. Sendo assim, clicamos no link **fasta**.

\
![](images/site5.png)\

\- Passo 6: ao clicar em **fasta**, nos abre uma página com a possibilidade apenas de voltar à página anterior ou clicar em **data**. Prosseguimos clicando em **data.**

\
![](images/site6.png)\

\- Passo 7: finalmente chegamos na página de interesse! Para ter acesso à esses arquivos devemos baixá-los no servidor linux usando (wget endereço_do_link) para que possamos realizar as análises.

\
![](images/site7.png)

## Objetivo do Webscraping

O objetivo do trabalho foi facilitar o acesso à esses dados presentes no site. Isso foi feito compilando os arquivos mais atuais do formato fasta de todos os organismos presentes no banco de dados em uma tabela.

## Metodologia utilizada

Para realizar o acesso à página foram usados dois pacotes do R, o `httr`e o `RSelenium` e para a manipulação dos dados foram utilizados pacotes pertencentes ao `tidyverse`. O `httr` foi utilizado para baixar o [html](https://tritrypdb.org/common/downloads/Current_Release/) da página dos arquivos considerados *Current_Release* através de uma requisição GET. Com isso o html em mãos os links foram acessados com o pacote `xml2` e manipulados com `stringr`. O `RSelenium` foi utilizado para recuperar da página inicial do [TriTrypDB](https://tritrypdb.org/tritrypdb/app/) o número atual do release, que se encontra no canto superior esquerdo da página. O pacote foi escolhido porque foi o único que conseguiu extrair a informação dessa página, provavelmente porque ela deve ser gerada dinamicamente. A intenção de recuperar o release atual é poder manter atualizada essa tabela conforme novas informações sejam depositadas no site. Com a informação do release coletada, ela foi novamente manipulada com o pacote `stringr`. Feito isso, eu gerei os sufixos de todos os arquivos que eu queria resgatar e juntei em um único objeto, que através de um loop utilizando a função for me permitiu gerar uma lista contendo uma tabela para cada tipo de arquivo. Por fim, utilizando o pacote `data.table` transformei os elementos da lista em um dataframe. Para visualizar o código utilizado para gerar a tabela, é só clicar no **Code** localizado logo abaixo.

```{r eval=FALSE}
#pacotes utilizados ------------
library(dplyr)
library(purrr)
library(stringr)
library(httr)
library(RSelenium)
library(xml2)
library(data.table)
library(tidyr)

#baixando a página ------------
u_tritrypdb <- "https://tritrypdb.org/common/downloads/Current_Release/"
r_tritrypdb <- httr::GET(u_tritrypdb, httr::write_disk(path = "tritrypdb.html", overwrite = TRUE))

#manipulacao dos dados obtidos --------- 
names <- r_tritrypdb |> 
  xml2::read_html() |> 
  xml2::xml_find_all("//pre//a") |> 
  xml2::xml_attr("href") |> 
  stringr::str_remove_all(pattern = "/")

#buscando o release atual ----------
u_tr <- "https://tritrypdb.org/tritrypdb/app/"
drv <- rsDriver(browser = "firefox")
ses <- drv$client
ses$navigate(u_tr)

release <- ses$findElements("xpath", "//*[@class='vpdb-HeaderBrandingSuperscript']")

release <- release |>
  purrr::map(\(x) x$getElementText()) |>
  purrr::map_chr(1) |> stringr::str_squish() 

release <- release |> 
  stringr::str_replace("Release ", "TriTrypDB-")

ses$quit()
rm(ses)

current <- release |> stringr::str_extract("^(.*? )") |> stringr::str_replace(" ", "_" )

#nomes necessários para gerar os links da tabela final -------
current_release <- "https://tritrypdb.org/common/downloads/Current_Release/"
CDS <- "_AnnotatedCDSs.fasta"
protein <- "_AnnotatedProteins.fasta"
transcripts <- "_AnnotatedTranscripts.fasta"
genome <- "_Genome.fasta "

links_temp <- paste0(current_release, names)

all <- c(CDS, protein, transcripts, genome)

#gerando a tabela final -----------
tables <- list()

for (i in all) {
  link <- paste0(links_temp, "/fasta", "/data/", current, names, i) |> 
    as.data.frame()
  
  colnames(link) <- "link"
  
  char <- 1:10 |> as.character()
  
  link_final <- link |> 
    mutate(test = link, type = i, release = current) |> 
    separate(test, into = char, sep = "/") |> 
    dplyr::select("7", type, release, "3", link) |> 
    dplyr::rename(species = "7", database = "3") |> 
    mutate(type = str_remove(string = type, pattern = "_"))
  
  link_final <- link_final |> 
    dplyr::filter(!str_detect(species, "="),
                 (!str_detect(species, "commondownloads")),
                 (!str_detect(species, "Build_number")))
  
  tables[[i]] <- link_final
}

data.table::rbindlist(tables) |> dplyr::arrange(species) |> readr::write_csv("tritrypDT.csv")
```

## Resultado obtido

Segue abaixo a tabela gerada. Ela contêm 5 colunas, sendo:\

1- **species**: nome da espécie depositada\
2- **type**: tipo do arquivo fasta gerado (pode ser CDS, proteína, transcrito ou genoma)\
3- **release**: qual o número do lançamento/distruibuição dos dados\
4- **database**: qual o banco de dados foi utilizado para extrair os arquivos\
5- **link**: link de cada arquivo para ser baixado com wget e ser analisado\

```{r}
readr::read_csv("tritrypDT.csv", show_col_types = FALSE) |> 
  reactable::reactable(defaultPageSize = 4, searchable = TRUE)
```

\
\
Abaixo, ilustro como foi feito o download de um arquivo através do link presente na tabela utilizando o comando:\
`wget link_que_deseja_baixar`

![](images/servidor.png)\
\
É interessante ressaltar que para todos os organismos, nem sempre todos os arquivos estarão disponíveis, portanto, alguns podem dar erro na hora do download.

## Perspectivas

Com o desenvolvimento da tabela, o próximo passo será automatizar a atualização semanal dela com o objetivo de deixá-la sempre atualizada na versão mais atual dos dados. Isso será feito via Github Actions e ainda não foi realizado pelo fato de não ter conseguido fazer o pacote `RSelenium` funcionar na máquina.
